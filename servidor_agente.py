"""
Servidor FastAPI con Streaming para Agente de IA
================================================

Este servidor simula un agente de IA que procesa consultas en m√∫ltiples pasos
y reporta su progreso en tiempo real usando Server-Sent Events (SSE).

Para ejecutar:
    pip install fastapi uvicorn
    python servidor_agente.py
    
El servidor estar√° disponible en http://localhost:8000
"""

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import AsyncGenerator, Optional
import asyncio
import json
from datetime import datetime
import logging

# Configurar logging para ver qu√© est√° pasando en el servidor
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Crear la aplicaci√≥n FastAPI
app = FastAPI(
    title="Agente IA con Streaming",
    description="Microservicio que procesa consultas complejas y reporta progreso en tiempo real",
    version="1.0.0"
)

# Configurar CORS para permitir peticiones desde el navegador
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producci√≥n, especifica los dominios permitidos
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Modelo Pydantic para validar la entrada del usuario


class ConsultaUsuario(BaseModel):
    """
    Modelo que define qu√© datos esperamos recibir del usuario.
    Pydantic se encargar√° de validar que los datos sean correctos.
    """
    query: str
    user_id: Optional[str] = "usuario_anonimo"

    class Config:
        """f"""
        schema_extra = {
            "example": {
                "query": "Analiza las ventas del √∫ltimo trimestre",
                "user_id": "usuario_123"
            }
        }


def emitir_evento_sse(tipo: str, mensaje: str, datos: Optional[dict] = None) -> str:
    """
    Formatea un evento en el protocolo Server-Sent Events (SSE).

    El formato SSE es muy espec√≠fico:
    - Cada l√≠nea debe comenzar con "data: "
    - El mensaje completo debe terminar con dos saltos de l√≠nea "\n\n"
    - Esto le indica al cliente que el evento est√° completo

    Args:
        tipo: El tipo de evento (start, step, response, complete, error)
        mensaje: El mensaje descriptivo del evento
        datos: Datos adicionales opcionales en formato diccionario

    Returns:
        String formateado en protocolo SSE
    """
    evento = {
        "type": tipo,
        "message": mensaje,
        "timestamp": datetime.now().isoformat(),
        "data": datos or {}
    }

    # Convertir a JSON y formatear como evento SSE
    json_str = json.dumps(evento, ensure_ascii=False)
    return f"data: {json_str}\n\n"


async def simular_clasificacion_llm(query: str) -> dict:
    """
    Simula la llamada a un LLM para clasificar el tipo de consulta.

    En tu implementaci√≥n real, aqu√≠ har√≠as una llamada a OpenAI, Anthropic,
    o tu LLM preferido para determinar qu√© tipo de procesamiento necesita
    la consulta del usuario.

    Por ahora, usamos una l√≥gica simple basada en palabras clave.
    """
    # Simular que el LLM toma tiempo en responder
    await asyncio.sleep(1)

    query_lower = query.lower()

    # Detectar saludos
    saludos = ["hola", "hey", "buenos d√≠as", "buenas tardes", "hi", "hello"]
    if any(saludo in query_lower for saludo in saludos):
        return {
            "tipo_plan": "respuesta_rapida",
            "confianza": 0.95,
            "razon": "Saludo detectado"
        }

    # Detectar consultas que requieren an√°lisis de datos
    palabras_analisis = ["analiza", "compara",
                         "ventas", "datos", "trimestre", "reporte"]
    if any(palabra in query_lower for palabra in palabras_analisis):
        return {
            "tipo_plan": "respuesta_investigativa",
            "confianza": 0.88,
            "razon": "Requiere an√°lisis de datos"
        }

    # Por defecto, asumir que es investigativa
    return {
        "tipo_plan": "respuesta_investigativa",
        "confianza": 0.70,
        "razon": "Consulta general que podr√≠a requerir investigaci√≥n"
    }


async def ejecutar_plan_rapido(query: str) -> AsyncGenerator[str, None]:
    """
    Ejecuta un plan simple para respuestas r√°pidas.

    Este generador as√≠ncrono va produciendo eventos usando 'yield'.
    Cada 'yield' env√≠a un evento al cliente inmediatamente.
    """
    logger.info(f"Ejecutando plan r√°pido para: {query}")

    # Paso 1: Procesando
    yield emitir_evento_sse(
        "step",
        "Procesando saludo y preparando respuesta...",
        {"plan": "rapido", "paso": 1}
    )
    await asyncio.sleep(0.5)

    # Paso 2: Respuesta
    yield emitir_evento_sse(
        "response",
        "¬°Hola! Soy tu agente de IA. Estoy aqu√≠ para ayudarte con an√°lisis de datos, "
        "consultas SQL, b√∫squeda en documentos y mucho m√°s. ¬øEn qu√© puedo asistirte hoy?",
        {"plan": "rapido", "tiempo_respuesta_segundos": 0.5}
    )

    # Paso 3: Completado
    yield emitir_evento_sse(
        "complete",
        "Plan r√°pido completado exitosamente",
        {"plan": "rapido"}
    )


async def simular_consulta_sql(query_sql: str, descripcion: str) -> dict:
    """
    Simula la ejecuci√≥n de una consulta SQL.

    En tu implementaci√≥n real, aqu√≠ conectar√≠as con tu base de datos
    usando asyncpg, aiomysql, o el driver as√≠ncrono correspondiente.
    """
    # Simular tiempo de ejecuci√≥n de la query
    await asyncio.sleep(2.5)

    # Simular resultados
    return {
        "query_ejecutada": query_sql,
        "filas_afectadas": 1523,
        "tiempo_ejecucion_ms": 2450,
        "columnas": ["categoria", "total_ventas", "promedio"],
        "muestra_resultados": [
            {"categoria": "Electr√≥nica", "total_ventas": 450000, "promedio": 1250},
            {"categoria": "Ropa", "total_ventas": 380000, "promedio": 890},
            {"categoria": "Alimentos", "total_ventas": 520000, "promedio": 650}
        ]
    }


async def simular_busqueda_documentos(terminos: str) -> dict:
    """
    Simula la b√∫squeda en documentos PDF u otros archivos.

    En tu implementaci√≥n real, aqu√≠ buscar√≠as en tu sistema de archivos,
    base de datos de documentos, o sistema de b√∫squeda vectorial.
    """
    await asyncio.sleep(2)

    return {
        "terminos_busqueda": terminos,
        "documentos_escaneados": 45,
        "documentos_relevantes": 7,
        "extractos": [
            "Las ventas del Q4 mostraron un crecimiento del 15% respecto al a√±o anterior...",
            "El an√°lisis comparativo indica que la categor√≠a de Electr√≥nica lidera el mercado..."
        ]
    }


async def ejecutar_plan_investigativo(query: str) -> AsyncGenerator[str, None]:
    """
    Ejecuta un plan complejo que simula m√∫ltiples pasos de investigaci√≥n.

    Este es el coraz√≥n de tu agente. Aqu√≠ orquestas todas las operaciones
    necesarias para responder consultas complejas, y vas reportando cada paso
    al usuario en tiempo real.
    """
    logger.info(f"Ejecutando plan investigativo para: {query}")

    # PASO 1: An√°lisis inicial
    yield emitir_evento_sse(
        "step",
        "Analizando tu consulta y determinando las fuentes de datos necesarias...",
        {"paso": 1, "total_pasos": 6, "fase": "analisis"}
    )
    await asyncio.sleep(1.5)

    yield emitir_evento_sse(
        "info",
        "Se identificaron 3 fuentes de datos relevantes: Base de datos SQL, "
        "Documentos hist√≥ricos, y Datos de mercado",
        {"fuentes": ["sql", "documentos", "mercado"]}
    )

    # PASO 2: Primera consulta SQL - Obtener totales
    yield emitir_evento_sse(
        "step",
        "Generando y ejecutando consulta SQL para obtener totales generales...",
        {"paso": 2, "total_pasos": 6, "fase": "sql_query_1"}
    )

    query_sql_1 = "SELECT SUM(monto) as total, COUNT(*) as registros FROM ventas WHERE fecha >= '2024-07-01' AND fecha <= '2024-09-30'"
    resultado_sql_1 = await simular_consulta_sql(query_sql_1, "totales generales")

    yield emitir_evento_sse(
        "sql_ejecutado",
        f"Consulta completada: {resultado_sql_1['filas_afectadas']} registros procesados",
        {
            "query": query_sql_1,
            "resultados": resultado_sql_1
        }
    )

    # PASO 3: Segunda consulta SQL - Datos agrupados
    yield emitir_evento_sse(
        "step",
        "Ejecutando segunda consulta SQL para an√°lisis por categor√≠as...",
        {"paso": 3, "total_pasos": 6, "fase": "sql_query_2"}
    )

    query_sql_2 = "SELECT categoria, SUM(monto) as total, AVG(monto) as promedio FROM ventas GROUP BY categoria ORDER BY total DESC"
    resultado_sql_2 = await simular_consulta_sql(query_sql_2, "agrupaci√≥n por categor√≠a")

    yield emitir_evento_sse(
        "sql_ejecutado",
        f"Datos agrupados obtenidos: {len(resultado_sql_2['muestra_resultados'])} categor√≠as analizadas",
        {
            "query": query_sql_2,
            "resultados": resultado_sql_2
        }
    )

    # PASO 4: Tercera consulta SQL - Tendencias temporales
    yield emitir_evento_sse(
        "step",
        "Analizando tendencias temporales con tercera consulta SQL...",
        {"paso": 4, "total_pasos": 6, "fase": "sql_query_3"}
    )

    query_sql_3 = "SELECT DATE_TRUNC('week', fecha) as semana, SUM(monto) as total FROM ventas GROUP BY semana ORDER BY semana"
    resultado_sql_3 = await simular_consulta_sql(query_sql_3, "tendencias semanales")

    yield emitir_evento_sse(
        "sql_ejecutado",
        "Tendencias temporales calculadas exitosamente",
        {
            "query": query_sql_3,
            "resultados": resultado_sql_3
        }
    )

    # PASO 5: B√∫squeda en documentos
    yield emitir_evento_sse(
        "step",
        "Buscando informaci√≥n contextual en documentos hist√≥ricos...",
        {"paso": 5, "total_pasos": 6, "fase": "busqueda_documentos"}
    )

    resultado_docs = await simular_busqueda_documentos("ventas trimestre an√°lisis")

    yield emitir_evento_sse(
        "documentos_procesados",
        f"Se escanearon {resultado_docs['documentos_escaneados']} documentos, "
        f"encontrando {resultado_docs['documentos_relevantes']} con informaci√≥n relevante",
        {"resultados": resultado_docs}
    )

    # PASO 6: S√≠ntesis y generaci√≥n de respuesta
    yield emitir_evento_sse(
        "step",
        "Sintetizando toda la informaci√≥n recopilada y generando respuesta final...",
        {"paso": 6, "total_pasos": 6, "fase": "sintesis"}
    )
    await asyncio.sleep(2)

    # Construir respuesta final basada en los resultados simulados
    respuesta_final = f"""
AN√ÅLISIS COMPLETO DEL √öLTIMO TRIMESTRE

üìä RESUMEN EJECUTIVO:
Durante el per√≠odo analizado (Q3 2024), se procesaron {resultado_sql_1['filas_afectadas']} transacciones 
de ventas. El an√°lisis multifuente revela patrones importantes para la toma de decisiones.

üí∞ TOTALES Y M√âTRICAS PRINCIPALES:
‚Ä¢ Total de registros procesados: {resultado_sql_1['filas_afectadas']:,}
‚Ä¢ Tiempo de procesamiento: {resultado_sql_1['tiempo_ejecucion_ms']}ms por consulta

üìà AN√ÅLISIS POR CATEGOR√çAS:
El an√°lisis revel√≥ {len(resultado_sql_2['muestra_resultados'])} categor√≠as principales:
‚Ä¢ Electr√≥nica: $450,000 (Promedio: $1,250 por transacci√≥n)
‚Ä¢ Ropa: $380,000 (Promedio: $890 por transacci√≥n)  
‚Ä¢ Alimentos: $520,000 (Promedio: $650 por transacci√≥n)

La categor√≠a de Alimentos lidera en volumen total, aunque Electr√≥nica tiene el ticket promedio m√°s alto.

üìÖ TENDENCIAS TEMPORALES:
El an√°lisis semanal muestra un patr√≥n de crecimiento sostenido durante el trimestre,
con picos notables en las √∫ltimas semanas del per√≠odo.

üìÑ CONTEXTO HIST√ìRICO:
La b√∫squeda en {resultado_docs['documentos_escaneados']} documentos hist√≥ricos proporcion√≥ 
contexto adicional. Los documentos relevantes indican que este rendimiento est√° 15% por encima 
del mismo per√≠odo del a√±o anterior.

‚úÖ CONCLUSIONES Y RECOMENDACIONES:
1. El rendimiento general supera las expectativas establecidas
2. La categor√≠a de Electr√≥nica presenta oportunidad de aumentar volumen
3. Se recomienda analizar las estrategias exitosas de Alimentos para replicarlas
4. Las tendencias semanales sugieren efectividad de las campa√±as actuales

Este an√°lisis integr√≥ datos de m√∫ltiples fuentes para proporcionar una visi√≥n completa del desempe√±o.
"""

    yield emitir_evento_sse(
        "response",
        respuesta_final.strip(),
        {
            "plan": "investigativo",
            "consultas_sql_ejecutadas": 3,
            "documentos_consultados": resultado_docs['documentos_escaneados'],
            "tiempo_total_aproximado_segundos": 14
        }
    )

    # Evento final de completado
    yield emitir_evento_sse(
        "complete",
        "Plan investigativo completado exitosamente. Todas las fuentes fueron consultadas.",
        {"plan": "investigativo", "exito": True}
    )


async def orquestador_principal(consulta: ConsultaUsuario) -> AsyncGenerator[str, None]:
    """
    Funci√≥n principal que orquesta todo el flujo del agente.

    Esta funci√≥n es como el director de orquesta: decide qu√© hacer bas√°ndose
    en la consulta del usuario y coordina todas las piezas del sistema.
    """
    try:
        logger.info(
            f"Nueva consulta recibida de {consulta.user_id}: {consulta.query}")

        # Evento 1: Inicio
        yield emitir_evento_sse(
            "start",
            "Iniciando procesamiento de tu consulta...",
            {
                "query": consulta.query,
                "user_id": consulta.user_id,
                "timestamp_inicio": datetime.now().isoformat()
            }
        )

        # Evento 2: Clasificaci√≥n del tipo de plan
        yield emitir_evento_sse(
            "step",
            "Clasificando el tipo de respuesta necesaria usando IA...",
            {"fase": "clasificacion"}
        )

        clasificacion = await simular_clasificacion_llm(consulta.query)

        yield emitir_evento_sse(
            "plan_seleccionado",
            f"Plan seleccionado: {clasificacion['tipo_plan']} (confianza: {clasificacion['confianza']:.0%})",
            clasificacion
        )

        # Evento 3: Ejecutar el plan correspondiente
        if clasificacion['tipo_plan'] == "respuesta_rapida":
            # Para respuestas r√°pidas, delegamos al generador especializado
            async for evento in ejecutar_plan_rapido(consulta.query):
                yield evento
        else:
            # Para consultas complejas, usamos el plan investigativo
            async for evento in ejecutar_plan_investigativo(consulta.query):
                yield evento

        logger.info(
            f"Consulta completada exitosamente para {consulta.user_id}")

    except Exception as e:
        # Si algo sale mal, enviamos un evento de error
        logger.error(f"Error procesando consulta: {str(e)}", exc_info=True)
        yield emitir_evento_sse(
            "error",
            f"Ocurri√≥ un error durante el procesamiento: {str(e)}",
            {
                "error_tipo": type(e).__name__,
                "error_detalle": str(e)
            }
        )


@app.post("/api/agente/consulta")
async def endpoint_consulta_streaming(consulta: ConsultaUsuario):
    """
    Endpoint principal que recibe consultas y retorna un stream de eventos.

    Este endpoint es especial porque no retorna JSON tradicional, sino un stream
    continuo de eventos Server-Sent Events que el cliente puede consumir en tiempo real.

    Args:
        consulta: Objeto con la query del usuario y metadatos

    Returns:
        StreamingResponse con eventos SSE
    """
    logger.info(
        f"Endpoint /api/agente/consulta llamado con query: {consulta.query}")

    return StreamingResponse(
        orquestador_principal(consulta),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Importante para Nginx
            "Access-Control-Allow-Origin": "*"
        }
    )


@app.get("/api/health")
async def health_check():
    """Endpoint simple para verificar que el servidor est√° funcionando."""
    return {
        "status": "healthy",
        "servicio": "agente-ia-streaming",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat()
    }


@app.get("/")
async def root():
    """P√°gina de bienvenida con informaci√≥n sobre el API."""
    return {
        "mensaje": "Bienvenido al Agente de IA con Streaming",
        "documentacion": "/docs",
        "health": "/api/health",
        "endpoint_principal": "POST /api/agente/consulta"
    }


if __name__ == "__main__":
    import uvicorn

    print("="*80)
    print("Iniciando servidor del Agente de IA con Streaming")
    print("="*80)
    print("\nEndpoints disponibles:")
    print("  ‚Ä¢ http://localhost:8000 - P√°gina de bienvenida")
    print("  ‚Ä¢ http://localhost:8000/docs - Documentaci√≥n interactiva")
    print("  ‚Ä¢ http://localhost:8000/api/health - Health check")
    print("  ‚Ä¢ POST http://localhost:8000/api/agente/consulta - Endpoint principal\n")
    print("Para probar el servidor, ejecuta cliente_agente.py en otra terminal")
    print("="*80)

    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
